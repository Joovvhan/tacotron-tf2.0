{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy as sp\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "fs = 22050\n",
    "frame_length_ms=50\n",
    "frame_shift_ms=12.5\n",
    "nsc = int(22050 * frame_length_ms / 1000)\n",
    "nov = nsc - int(22050 * frame_shift_ms / 1000)\n",
    "nhop = int(22050 * frame_shift_ms / 1000)\n",
    "eps = 1e-10\n",
    "db_ref = 100\n",
    "\n",
    "chars = ' ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!\\'(),-.:;?'\n",
    "\n",
    "num_tokens = len(chars)\n",
    "\n",
    "embed_size = 256\n",
    "\n",
    "K = 16\n",
    "\n",
    "num_conv1d_filters = 128\n",
    "\n",
    "prenet_size = [256, 128]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"../datasets/metadata.csv\"\n",
    "\n",
    "with open(meta_path, encoding='utf-8') as f:\n",
    "    metadata = np.array([line.strip().split('|') for line in f])\n",
    "#     hours = sum((int(x[2]) for x in metadata)) * frame_shift_ms / (3600 * 1000)\n",
    "#     log('Loaded metadata for %d examples (%.2f hours)' % (len(metadata), hours))\n",
    "\n",
    "metadata = metadata[:32, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_name_list = []\n",
    "\n",
    "for data in metadata:\n",
    "    wav_name = '{}.wav'.format(data[0])\n",
    "    wave_name_list.append(wav_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5029378339d45959547f3bc9d24d2ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Preprocessing Step\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data_folder = \"../datasets/wavs\"\n",
    "specgram_folder = \"../datasets/specgrams\"\n",
    "mel_folder = \"../datasets/mels\"\n",
    "\n",
    "for wav_name in tqdm(wave_name_list):\n",
    "    wav_path = os.path.join(data_folder, wav_name)\n",
    "    \n",
    "    npy_name = wav_name.replace('.wav', '.npy')\n",
    "    \n",
    "    specgram_path = os.path.join(specgram_folder, npy_name)\n",
    "    mel_path = os.path.join(mel_folder, npy_name)\n",
    "    \n",
    "    y, sr = librosa.core.load(wav_path)\n",
    "    \n",
    "    f, t, Zxx = sp.signal.stft(y, fs=sr, nperseg=nsc, noverlap=nov)\n",
    "\n",
    "    Sxx = np.abs(Zxx)\n",
    "    Sxx = np.maximum(Sxx, eps)\n",
    "\n",
    "    # plt.figure(figsize=(20,20))\n",
    "    # plt.imshow(20*np.log10(Sxx), origin='lower')\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "\n",
    "    mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "    log_specgram = 20*np.log10(Sxx)\n",
    "\n",
    "    norm_log_specgram = (log_specgram + db_ref) / db_ref\n",
    "\n",
    "    log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "\n",
    "    norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref\n",
    "    \n",
    "    np.save(specgram_path, norm_log_specgram)\n",
    "    np.save(mel_path, norm_log_mel_specgram)\n",
    "    \n",
    "#     print(norm_log_mel_specgram.shape[1])\n",
    "    \n",
    "\n",
    "#     plt.figure(figsize=(16,9))\n",
    "#     plt.imshow(norm_log_specgram, origin='lower', aspect='auto')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure(figsize=(16,9))\n",
    "#     plt.imshow(norm_log_mel_specgram, origin='lower', aspect='auto')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2token(text):\n",
    "    text_len = len(text)\n",
    "    num_list = -1 * np.ones(text_len)\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        num_list[i] = chars.find(char)\n",
    "        \n",
    "    assert len(num_list) == text_len, \"Tokenization Failed\"\n",
    "        \n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    text = metadata[i, 1]\n",
    "    text_tokenized = text2token(text)\n",
    "    tokenized_list.append(text_tokenized)\n",
    "    \n",
    "max_token_len = max([len(tokenized) for tokenized in tokenized_list])\n",
    "batched_token = np.zeros((batch_size, max_token_len))\n",
    "\n",
    "for i in range(batch_size):  \n",
    "    tokenized_len = len(tokenized_list[i])\n",
    "    batched_token[i, :tokenized_len] = tokenized_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 155)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(None, ))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(num_tokens, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_prenet_layer_list = [tf.keras.layers.Dense(prenet_size[0], activation='relu', input_shape=(None, embed_size)),\n",
    "                             tf.keras.layers.Dropout(0.5),\n",
    "                             tf.keras.layers.Dense(prenet_size[1], activation='relu'),\n",
    "                             tf.keras.layers.Dropout(0.5)]\n",
    "\n",
    "encoder_prenet = tf.keras.Sequential(encoder_prenet_layer_list, name='Encoder_Prenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 256)\n",
      "(None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "x = embedding_layer(inputs)\n",
    "print(x.shape)\n",
    "x = encoder_prenet(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_filter_list = [tf.keras.layers.Conv1D(kernel_size=k+1,\n",
    "                                filters=128,\n",
    "                                activation='relu', \n",
    "                                padding='same',\n",
    "                                input_shape=(None, 128)) for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_results = []\n",
    "\n",
    "for conv_k in conv1d_filter_list:\n",
    "    conv_k_result = conv_k(x)\n",
    "    intermediate_results.append(conv_k_result)\n",
    "    \n",
    "outputs = tf.concat(intermediate_results, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 2048])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batched_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 256)         16128     \n",
      "_________________________________________________________________\n",
      "Encoder_Prenet (Sequential)  (None, None, 128)         98688     \n",
      "=================================================================\n",
      "Total params: 114,816\n",
      "Trainable params: 114,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvFilterBank(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ConvFilterBank, self).__init__()\n",
    "#         self.num_outputs = np.sum([128 * k for k in range(K)])\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1d_filter_list = [tf.keras.layers.Conv1D(kernel_size=k+1,\n",
    "                                filters=128,\n",
    "                                activation='relu', \n",
    "                                padding='same',\n",
    "                                input_shape=(None, 128)) for k in range(K)]\n",
    "\n",
    "    def call(self, input_):\n",
    "        intermediate_results = []\n",
    "        \n",
    "        for k in range(K):\n",
    "            conv_k_result = self.conv1d_filter_list[k](input_)\n",
    "            intermediate_results.append(conv_k_result)\n",
    "        \n",
    "        output = tf.concat(intermediate_results, axis = -1) \n",
    "        return output\n",
    "#         return tf.concat([self.conv1d_filter_list[k](input_) for k in range(K)], axis=-1)\n",
    "#         return tf.concat([self.conv1d_filter_list[k](input_) ], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_filter_bank = ConvFilterBank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_conv1d = tf.keras.Sequential([embedding_layer, encoder_prenet, conv1d_filter_bank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 155, 256)\n",
      "(4, 155, 128)\n"
     ]
    }
   ],
   "source": [
    "embedded_batch = embedding_layer(batched_token)\n",
    "print(embedded_batch.shape)\n",
    "prenet_result = encoder_prenet(embedded_batch)\n",
    "print(prenet_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bank_result = conv1d_filter_bank(prenet_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 2048])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_bank_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_conv1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bank_result = stacked_conv1d(batched_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv1d_filter_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = conv1d(encoded_result)\n",
    "conv_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvFilterBanks(Model):\n",
    "    def __init__(self):\n",
    "        super(ConvFilterBanks, self).__init__()\n",
    "        self.filters = [tf.keras.layers.Conv1D(kernel_size = k, \n",
    "                                              filters = num_conv1d_filters,\n",
    "                                              activation='relu',\n",
    "                                              input_shape=(None, embed_size))\n",
    "                                              for k in range(K)]\n",
    "\n",
    "    def call(self, x):\n",
    "        outputs = []\n",
    "        for i, layer in enumerate(self.filters):\n",
    "            outputs.append(self.filters[i](x))\n",
    "            \n",
    "        output = tf.concat(outputs, 0)\n",
    "\n",
    "        return output\n",
    "    \n",
    "conv1d_banks = ConvFilterBanks()\n",
    "\n",
    "model = tf.keras.Sequential([encoder_prenet, conv1d_banks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(embedded_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvFilterBanks(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ConvFilterBanks, self).__init__()\n",
    "        self.layers = [tf.keras.layers.Conv1D(kernel_size = k, \n",
    "                                              filters = num_conv1d_filters,\n",
    "                                              activation='relu',\n",
    "                                              input_shape=(None, embed_size)) for k in range(K)]\n",
    "        self.num_outputs = [None, None, embed_size * K * num_conv1d_filters]\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_variable(\"kernel\", \n",
    "                                        shape=[int(input_shape[-1]), \n",
    "                                               self.num_outputs])\n",
    "    \n",
    "    def call(self, input):\n",
    "\n",
    "        for i, layer in enumerate(layers):\n",
    "            if i == 0:\n",
    "                output = self.layers[i](input)\n",
    "            else:\n",
    "                output = tf.concat(output, self.layers[i](input))\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = ConvFilterBanks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_bank_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     IMG_SHAPE = (256, 256, 3)\n",
    "#     img_inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "#     conv_1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(img_inputs)\n",
    "#     maxpool_1 = tf.keras.layers.MaxPooling2D((2, 2))(conv_1)\n",
    "#     conv_2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(maxpool_1)\n",
    "#     maxpool_2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_2)\n",
    "#     conv_3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(maxpool_2)\n",
    "#     flatten = tf.keras.layers.Flatten()(conv_3)\n",
    "#     dense_1 = tf.keras.layers.Dense(64, activation='relu')(flatten)\n",
    "#     output = tf.keras.layers.Dense(10, activation='softmax')(dense_1)\n",
    "\n",
    "#     model = tf.keras.Model(inputs=img_inputs, outputs=output)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casual_conv_layers = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    if i == 0:\n",
    "        conv1d = tf.keras.layers.Conv1D(filters=1, kernel_size=2, dilation_rate=2**i, padding='same', input_shape=[2**10, 1],\n",
    "        activation=\"softmax\",use_bias=True)\n",
    "    else:\n",
    "        conv1d = tf.keras.layers.Conv1D(filters=1, kernel_size=2, dilation_rate=2**i, padding='same', input_shape=[2**10, 1],\n",
    "        activation=\"softmax\",use_bias=True)\n",
    "\n",
    "    casual_conv_layers.append(conv1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(casual_conv_layers)\n",
    "# model.add(casual_conv_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(np.random.random(4 * 1024).reshape(4, 1024, 1).astype(np.float32))\n",
    "y = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
