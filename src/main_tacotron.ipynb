{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy as sp\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "fs = 22050\n",
    "frame_length_ms=50\n",
    "frame_shift_ms=12.5\n",
    "nsc = int(22050 * frame_length_ms / 1000)\n",
    "nov = nsc - int(22050 * frame_shift_ms / 1000)\n",
    "nhop = int(22050 * frame_shift_ms / 1000)\n",
    "eps = 1e-10\n",
    "db_ref = 100\n",
    "\n",
    "chars = ' ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz!\\'(),-.:;?'\n",
    "\n",
    "num_tokens = len(chars)\n",
    "\n",
    "embed_size = 256\n",
    "\n",
    "K = 16\n",
    "\n",
    "num_conv1d_filters = 128\n",
    "\n",
    "prenet_size = [256, 128]\n",
    "\n",
    "conv_proj_size = [128, 128]\n",
    "\n",
    "attention_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = \"../datasets/metadata.csv\"\n",
    "\n",
    "with open(meta_path, encoding='utf-8') as f:\n",
    "    metadata = np.array([line.strip().split('|') for line in f])\n",
    "#     hours = sum((int(x[2]) for x in metadata)) * frame_shift_ms / (3600 * 1000)\n",
    "#     log('Loaded metadata for %d examples (%.2f hours)' % (len(metadata), hours))\n",
    "\n",
    "metadata = metadata[:32, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_name_list = []\n",
    "\n",
    "for data in metadata:\n",
    "    wav_name = '{}.wav'.format(data[0])\n",
    "    wave_name_list.append(wav_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a24ffc9f13ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8982d10edc364d55b28c839b79a2cefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Preprocessing Step\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data_folder = \"../datasets/wavs\"\n",
    "specgram_folder = \"../datasets/specgrams\"\n",
    "mel_folder = \"../datasets/mels\"\n",
    "\n",
    "for wav_name in tqdm(wave_name_list):\n",
    "    wav_path = os.path.join(data_folder, wav_name)\n",
    "    \n",
    "    npy_name = wav_name.replace('.wav', '.npy')\n",
    "    \n",
    "    specgram_path = os.path.join(specgram_folder, npy_name)\n",
    "    mel_path = os.path.join(mel_folder, npy_name)\n",
    "    \n",
    "    y, sr = librosa.core.load(wav_path)\n",
    "    \n",
    "    f, t, Zxx = sp.signal.stft(y, fs=sr, nperseg=nsc, noverlap=nov)\n",
    "\n",
    "    Sxx = np.abs(Zxx)\n",
    "    Sxx = np.maximum(Sxx, eps)\n",
    "\n",
    "    # plt.figure(figsize=(20,20))\n",
    "    # plt.imshow(20*np.log10(Sxx), origin='lower')\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    mel_filters = librosa.filters.mel(sr=fs, n_fft=nsc, n_mels=n_mels)\n",
    "\n",
    "    mel_specgram = np.matmul(mel_filters, Sxx)\n",
    "\n",
    "    log_specgram = 20*np.log10(Sxx)\n",
    "\n",
    "    norm_log_specgram = (log_specgram + db_ref) / db_ref\n",
    "\n",
    "    log_mel_specgram = 20 * np.log10(np.maximum(mel_specgram, eps))\n",
    "\n",
    "    norm_log_mel_specgram = (log_mel_specgram + db_ref) / db_ref\n",
    "    \n",
    "    np.save(specgram_path, norm_log_specgram)\n",
    "    np.save(mel_path, norm_log_mel_specgram)\n",
    "    \n",
    "#     print(norm_log_mel_specgram.shape[1])\n",
    "    \n",
    "\n",
    "#     plt.figure(figsize=(16,9))\n",
    "#     plt.imshow(norm_log_specgram, origin='lower', aspect='auto')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure(figsize=(16,9))\n",
    "#     plt.imshow(norm_log_mel_specgram, origin='lower', aspect='auto')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2token(text):\n",
    "    text_len = len(text)\n",
    "    num_list = -1 * np.ones(text_len)\n",
    "    \n",
    "    for i, char in enumerate(text):\n",
    "        num_list[i] = chars.find(char)\n",
    "        \n",
    "    assert len(num_list) == text_len, \"Tokenization Failed\"\n",
    "        \n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_list = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    text = metadata[i, 1]\n",
    "    text_tokenized = text2token(text)\n",
    "    tokenized_list.append(text_tokenized)\n",
    "    \n",
    "max_token_len = max([len(tokenized) for tokenized in tokenized_list])\n",
    "batched_token = np.zeros((batch_size, max_token_len))\n",
    "\n",
    "for i in range(batch_size):  \n",
    "    tokenized_len = len(tokenized_list[i])\n",
    "    batched_token[i, :tokenized_len] = tokenized_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = max_token_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 155)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(None, ))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(num_tokens, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_prenet_layer_list = [tf.keras.layers.Dense(prenet_size[0], activation='relu', input_shape=(None, embed_size)),\n",
    "                             tf.keras.layers.Dropout(0.5),\n",
    "                             tf.keras.layers.Dense(prenet_size[1], activation='relu'),\n",
    "                             tf.keras.layers.Dropout(0.5)]\n",
    "\n",
    "encoder_prenet = tf.keras.Sequential(encoder_prenet_layer_list, name='encoder_prenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1d_filter_list = [tf.keras.layers.Conv1D(kernel_size=k+1,\n",
    "#                                 filters=128,\n",
    "#                                 activation='relu', \n",
    "#                                 padding='same',\n",
    "#                                 input_shape=(None, 128)) for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate_results = []\n",
    "\n",
    "# for conv_k in conv1d_filter_list:\n",
    "#     conv_k_result = conv_k(x)\n",
    "#     intermediate_results.append(conv_k_result)\n",
    "    \n",
    "# outputs = tf.concat(intermediate_results, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(batched_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvFilterBank(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(ConvFilterBank, self).__init__()\n",
    "        self.num_outputs = num_conv1d_filters * K\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1d_filter_list = [tf.keras.layers.Conv1D(kernel_size=k+1,\n",
    "                                filters=num_conv1d_filters,\n",
    "                                activation='relu', \n",
    "                                padding='same',\n",
    "                                input_shape=(None, 128)) for k in range(K)]\n",
    "        self.batch_norm_list = [tf.keras.layers.BatchNormalization(trainable=True) \n",
    "                                for k in range(K)]\n",
    "\n",
    "    def call(self, input_):\n",
    "        intermediate_results = []\n",
    "        \n",
    "        for k in range(K):\n",
    "            conv_k_result = self.conv1d_filter_list[k](input_)\n",
    "            output = self.batch_norm_list[k](conv_k_result)\n",
    "            intermediate_results.append(output)\n",
    "        \n",
    "        outputs = tf.concat(intermediate_results, axis = -1) \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_filter_bank = ConvFilterBank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stacked_conv1d = tf.keras.Sequential([embedding_layer, encoder_prenet, conv1d_filter_bank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 256)         16128     \n",
      "_________________________________________________________________\n",
      "encoder_prenet (Sequential)  (None, None, 128)         98688     \n",
      "_________________________________________________________________\n",
      "conv_filter_bank (ConvFilter (None, None, 2048)        2238464   \n",
      "=================================================================\n",
      "Total params: 2,353,280\n",
      "Trainable params: 2,349,184\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "stacked_conv1d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 155, 256)\n",
      "(4, 155, 128)\n"
     ]
    }
   ],
   "source": [
    "embedded_batch = embedding_layer(batched_token)\n",
    "print(embedded_batch.shape)\n",
    "prenet_result = encoder_prenet(embedded_batch)\n",
    "print(prenet_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_bank_result = stacked_conv1d(batched_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 2048])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_bank_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.pooling.MaxPooling1D at 0x1d92fbc9898>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.MaxPool1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 256)\n",
      "(None, None, 128)\n",
      "Tensor(\"conv_filter_bank_1/Identity:0\", shape=(None, None, 2048), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = embedding_layer(inputs)\n",
    "print(x.shape)\n",
    "x = encoder_prenet(x)\n",
    "print(x.shape)\n",
    "x = conv1d_filter_bank(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_layer = tf.keras.layers.MaxPool1D(pool_size=2, strides=1, padding='same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_result = pooling_layer(filter_bank_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 2048])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooling_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_proj_layer_list = [tf.keras.layers.Conv1D(kernel_size=3,\n",
    "                                              filters=conv_proj_size[0], \n",
    "                                              activation='relu',\n",
    "                                              padding='same',\n",
    "                                              input_shape=(None, num_conv1d_filters * K)),\n",
    "                        tf.keras.layers.BatchNormalization(trainable=True),\n",
    "                        tf.keras.layers.Conv1D(kernel_size=3,\n",
    "                                               filters=conv_proj_size[1],\n",
    "                                               padding='same')]\n",
    "\n",
    "conv_proj_layer = tf.keras.Sequential(conv_proj_layer_list, name='conv_proj_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_proj_layer(pooling_result).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_proj_layer\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 128)         786560    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         49280     \n",
      "=================================================================\n",
      "Total params: 836,352\n",
      "Trainable params: 836,096\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_proj_layer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None)\n",
      "(None, None, 256)\n",
      "(None, None, 128)\n",
      "(None, None, 2048)\n",
      "(None, None, 2048)\n",
      "(None, None, 128)\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(None, ))\n",
    "print(inputs.shape)\n",
    "x = embedding_layer(inputs)\n",
    "print(x.shape)\n",
    "encoder_outputs = encoder_prenet(x)\n",
    "print(encoder_outputs.shape)\n",
    "x = conv1d_filter_bank(encoder_outputs)\n",
    "print(x.shape)\n",
    "x = pooling_layer(x)\n",
    "print(x.shape)\n",
    "conv_proj_outputs = conv_proj_layer(x)\n",
    "print(conv_proj_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_result = tf.add(encoder_outputs, conv_proj_outputs, name='residual_connection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(HighwayLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.T =  tf.keras.layers.Dense(input_shape=[None, None, conv_proj_size[-1]],\n",
    "                                        units=conv_proj_size[-1],\n",
    "                                        activation='sigmoid',\n",
    "                                        name='T', \n",
    "                                        bias_initializer=tf.constant_initializer(-1.0))\n",
    "        self.H = tf.keras.layers.Dense(input_shape=[None, None, conv_proj_size[-1]],\n",
    "                                       units=conv_proj_size[-1], \n",
    "                                       activation='relu',\n",
    "                                       name='H')\n",
    "\n",
    "    def call(self, input_):\n",
    "        outputs = self.H(input_) * self.T(input_) + input_ * (1 - self.T(input_))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_layer_list = [HighwayLayer(),\n",
    "                      HighwayLayer(),\n",
    "                      HighwayLayer(),\n",
    "                      HighwayLayer()]\n",
    "\n",
    "highway_network = tf.keras.Sequential(highway_layer_list, name='highway_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "highway_result = highway_network(residual_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=highway_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    16128       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_prenet (Sequential)     (None, None, 128)    98688       embedding[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_filter_bank (ConvFilterBan (None, None, 2048)   2238464     encoder_prenet[3][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 2048)   0           conv_filter_bank[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_proj_layer (Sequential)    (None, None, 128)    836352      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_residual_connection [(None, None, 128)]  0           encoder_prenet[3][0]             \n",
      "                                                                 conv_proj_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "highway_layer (Sequential)      (None, None, 128)    132096      tf_op_layer_residual_connection[0\n",
      "==================================================================================================\n",
      "Total params: 3,321,728\n",
      "Trainable params: 3,317,376\n",
      "Non-trainable params: 4,352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 128])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batched_token).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirec_rnn_layer = tf.keras.layers.Bidirectional(\n",
    "                      tf.keras.layers.GRU(128, \n",
    "                                          return_sequences=True,\n",
    "                                          return_state=False),\n",
    "                      merge_mode=\"concat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_outputs = bidirec_rnn_layer(highway_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_hidden_state(batch_size, enc_units):\n",
    "    return [tf.zeros((batch_size, enc_units)), tf.zeros((batch_size, enc_units))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = initialize_hidden_state(4, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_outputs = bidirec_rnn_layer(highway_result, initial_state = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_5/Identity:0' shape=(4, None, 256) dtype=float32>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden = rnn_outputs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    16128       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_prenet (Sequential)     (None, None, 128)    98688       embedding[2][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_filter_bank (ConvFilterBan (None, None, 2048)   2238464     encoder_prenet[3][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 2048)   0           conv_filter_bank[2][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_proj_layer (Sequential)    (None, None, 128)    836352      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_residual_connection [(None, None, 128)]  0           encoder_prenet[3][0]             \n",
      "                                                                 conv_proj_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "highway_layer (Sequential)      (None, None, 128)    132096      tf_op_layer_residual_connection[0\n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) multiple             198144      highway_layer[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,519,872\n",
      "Trainable params: 3,515,520\n",
      "Non-trainable params: 4,352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=rnn_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(batched_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 155, 256])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([155, 1, 256])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(result[1], 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://www.tensorflow.org/beta/tutorials/text/nmt_with_attention\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "class DecoderPrenet(tf.keras.Model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_results = model(batched_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = BahdanauAttention(attention_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = attention_layer(states, rnn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = attention_layer(rnn_states, rnn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batched_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batched_token)[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
